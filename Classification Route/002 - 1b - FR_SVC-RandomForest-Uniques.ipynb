{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98de65b8-0c27-4604-bed8-f04c38c188c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "337ddee7-6cbc-472e-9ac2-a98a014d9bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "# Define the data types for each column to optimize memory usage\n",
    "dtype_spec = {\n",
    "    'Em_on_target': 'float32',\n",
    "    'Fuel consumption': 'float32',\n",
    "    'Engine_cm3': 'float32',\n",
    "    'Electric range (km)': 'float32',\n",
    "    'Kg_veh': 'float32',\n",
    "    'Test_mass': 'float32',\n",
    "    'Power_KW': 'float32',\n",
    "    'El_Consumpt_whkm': 'float32',\n",
    "    'Energy': 'category',\n",
    "    'Fuel_mode': 'category',\n",
    "    'Brand': 'category',\n",
    "    'Veh_type': 'category',\n",
    "    'Veh_Model': 'category',\n",
    "    'year': 'float32',\n",
    "    'Version': 'category'\n",
    "}\n",
    "columns = ['Em_on_target', 'Fuel consumption', 'Engine_cm3', 'Electric range (km)', 'Kg_veh', 'Test_mass', 'Power_KW', 'El_Consumpt_whkm', 'Energy', 'Fuel_mode', 'Brand', 'Veh_type', 'Veh_Model','year','Version','Country']\n",
    "df = pd.read_csv('/Users/livalacaisse/Documents/DataScience/CO2/000-C02 First Delivery/Cleaned_countries/FR_Cleaned.csv', usecols=columns, dtype=dtype_spec, low_memory=False)\n",
    "# Convert data types after inspection\n",
    "df['Engine_cm3'] = pd.to_numeric(df['Engine_cm3'], errors='coerce').astype('float32').fillna(0).astype('int32')\n",
    "\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "653a9661-316a-437c-823e-af19bf85ab50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     NaN Count  NaN Percentage\n",
      "Country                      0             0.0\n",
      "Veh_type                     0             0.0\n",
      "Version                      0             0.0\n",
      "Brand                        0             0.0\n",
      "Veh_Model                    0             0.0\n",
      "Kg_veh                       0             0.0\n",
      "Test_mass                    0             0.0\n",
      "Energy                       0             0.0\n",
      "Fuel_mode                    0             0.0\n",
      "Engine_cm3                   0             0.0\n",
      "Power_KW                     0             0.0\n",
      "El_Consumpt_whkm             0             0.0\n",
      "year                         0             0.0\n",
      "Fuel consumption             0             0.0\n",
      "Electric range (km)          0             0.0\n",
      "Em_on_target                 0             0.0\n"
     ]
    }
   ],
   "source": [
    "# NaN status\n",
    "# Calculate NaN counts and percentages for each column\n",
    "nan_counts = df.isna().sum()\n",
    "nan_percentages = (df.isna().sum() / len(df)) * 100\n",
    "\n",
    "# Create a DataFrame to display the NaN information in a tidy format\n",
    "nan_df = pd.DataFrame({\n",
    "    'NaN Count': nan_counts,\n",
    "    'NaN Percentage': nan_percentages\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(nan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42d60b9c-46f3-4697-9e6b-0ff1f5b880ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select relevant features and target\n",
    "features = ['Fuel consumption', 'Engine_cm3', 'Electric range (km)', 'Kg_veh', 'Test_mass', 'Power_KW', 'El_Consumpt_whkm', 'Energy', 'Fuel_mode', 'Brand', 'Veh_type', 'Veh_Model','year','Version']\n",
    "target = 'Em_on_target'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c010702-c1b1-4f81-bfbd-10e78a710ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Categorical and numerical features\n",
    "categorical_features = ['Energy', 'Fuel_mode', 'Brand', 'Veh_type', 'Veh_Model','Version']\n",
    "numerical_features = [feat for feat in features if feat not in categorical_features]\n",
    "\n",
    "# Creating the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Pipeline for Random Forest\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, max_features='sqrt'))\n",
    "])\n",
    "\n",
    "# Pipeline for SVM\n",
    "svm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e843086-10d7-4c5d-9c9b-2d71d61cf41f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9998089032868634\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     95011\n",
      "         1.0       1.00      1.00      1.00     14881\n",
      "\n",
      "    accuracy                           1.00    109892\n",
      "   macro avg       1.00      1.00      1.00    109892\n",
      "weighted avg       1.00      1.00      1.00    109892\n",
      "\n",
      "SVM Accuracy: 0.99976340406945\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     95011\n",
      "         1.0       1.00      1.00      1.00     14881\n",
      "\n",
      "    accuracy                           1.00    109892\n",
      "   macro avg       1.00      1.00      1.00    109892\n",
      "weighted avg       1.00      1.00      1.00    109892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Fit, predict, and evaluate the Random Forest model\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_pred = rf_pipeline.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_pred))\n",
    "\n",
    "# Fit, predict, and evaluate the SVM model\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "svm_pred = svm_pipeline.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(f'SVM Accuracy: {svm_accuracy}')\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "195c2d6c-74c4-4de7-ada8-a90b2fc6a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Optimisation wiht RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84be6b83-99d8-4072-a5ad-e41b1189e289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Random search parameters for Random Forest\n",
    "rf_param_dist = {\n",
    "    'classifier__max_depth': randint(3, 20),\n",
    "    'classifier__min_samples_split': randint(2, 20),\n",
    "    'classifier__min_samples_leaf': randint(1, 10),\n",
    "    'classifier__max_features': ['sqrt', None],  # assuming you've adjusted this from 'auto' as discussed previously\n",
    "    'classifier__n_estimators': randint(100, 200)  # Example parameter for number of trees\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d61e8a85-9322-410e-bd75-b15561229dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__max_depth': 19, 'classifier__max_features': None, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 6, 'classifier__n_estimators': 195}\n",
      "Best cross-validated accuracy: 0.9998202764557607\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the RandomizedSearchCV\n",
    "rf_random_search = RandomizedSearchCV(\n",
    "    estimator=rf_pipeline, \n",
    "    param_distributions=rf_param_dist, \n",
    "    n_iter=50,  # Adjusted to match the actual size of the parameter space\n",
    "    cv=2, \n",
    "    scoring='accuracy', \n",
    "    n_jobs=-1, \n",
    "    random_state=42\n",
    ")\n",
    "rf_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best model parameters and accuracy\n",
    "print(\"Best Parameters:\", rf_random_search.best_params_)\n",
    "print(\"Best cross-validated accuracy:\", rf_random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df2350f8-c92a-4277-94a2-aa9e6c234315",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random search parameters for SVM\n",
    "svm_param_dist = {\n",
    "    'classifier__C': np.logspace(-3, 2, 6),\n",
    "    'classifier__kernel': ['rbf', 'linear'],\n",
    "    'classifier__gamma': ['scale', 'auto', 0.1, 1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cb67186-8ae1-4ab3-8a45-e195da214332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__kernel': 'rbf', 'classifier__gamma': 'scale', 'classifier__C': 100.0}\n",
      "Best cross-validated accuracy: 0.9998271014004787\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the RandomizedSearchCV\n",
    "svm_random_search = RandomizedSearchCV(estimator=svm_pipeline, param_distributions=svm_param_dist, n_iter=20, cv=2, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "svm_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and parameters\n",
    "print(\"Best Parameters:\", svm_random_search.best_params_)\n",
    "print(\"Best cross-validated accuracy:\", svm_random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93d47a83-765a-4ae7-b5c8-dad5d7294391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5aec57fb-9982-426d-a5d1-ba5ea49ce995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get_feature_names_out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(rf_random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_importances_\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m     feature_importances_rf \u001b[38;5;241m=\u001b[39m rf_random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[0;32m----> 4\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransformers_[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m preprocessor\u001b[38;5;241m.\u001b[39mtransformers_[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mget_feature_names_out()\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Adjust this if your feature names are stored differently\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame to view the feature importances\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     feature_importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_names,\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_importances_rf\n\u001b[1;32m     10\u001b[0m     })\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get_feature_names_out'"
     ]
    }
   ],
   "source": [
    "# Feature importance from Random Forest\n",
    "if hasattr(rf_random_search.best_estimator_.named_steps['classifier'], 'feature_importances_'):\n",
    "    feature_importances_rf = rf_random_search.best_estimator_.named_steps['classifier'].feature_importances_\n",
    "    feature_names = preprocessor.transformers_[0][-1] + preprocessor.transformers_[1][-1].get_feature_names_out().tolist()  # Adjust this if your feature names are stored differently\n",
    "\n",
    "    # Create a DataFrame to view the feature importances\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importances_rf\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    print(\"Random Forest Feature Importances:\")\n",
    "    print(feature_importance_df)\n",
    "else:\n",
    "    print(\"No feature_importances_ attribute available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a9b68-df7f-4e7e-9a64-902198b7327b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature importance for SVM\n",
    "if 'linear' in svm_random_search.best_params_['classifier__kernel']:\n",
    "    svm_coefficients = svm_random_search.best_estimator_.named_steps['classifier'].coef_[0]\n",
    "    feature_names = preprocessor.transformers_[0][-1] + preprocessor.transformers_[1][-1].get_feature_names_out().tolist()  # Adjust if different\n",
    "\n",
    "    svm_feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': svm_coefficients\n",
    "    }).sort_values(by='Importance', key=abs, ascending=False)\n",
    "\n",
    "    print(\"SVM Feature Importances (Linear Kernel):\")\n",
    "    print(svm_feature_importance_df)\n",
    "else:\n",
    "    print(\"SVM is using a non-linear kernel; feature importance is not directly interpretable.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3de5ac-8a6b-421a-a195-2d73aa251c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
