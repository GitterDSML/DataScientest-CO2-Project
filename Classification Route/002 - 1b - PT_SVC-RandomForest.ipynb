{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98de65b8-0c27-4604-bed8-f04c38c188c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337ddee7-6cbc-472e-9ac2-a98a014d9bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('PtCO2180424.csv')\n",
    "var_to_include = ['Em_on_target', 'Fuel consumption', 'Engine_cm3', 'Electric range (km)', 'Kg_veh', 'Test_mass', 'Power_KW', 'El_Consumpt_whkm', 'Energy', 'Fuel_mode', 'Brand', 'Veh_type']\n",
    "dfdt = df[var_to_include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42d60b9c-46f3-4697-9e6b-0ff1f5b880ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select relevant features and target\n",
    "features = ['Fuel consumption', 'Engine_cm3', 'Electric range (km)', 'Kg_veh', 'Test_mass', 'Power_KW', 'El_Consumpt_whkm', 'Energy', 'Fuel_mode', 'Brand', 'Veh_type']\n",
    "target = 'Em_on_target'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c010702-c1b1-4f81-bfbd-10e78a710ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Categorical and numerical features\n",
    "categorical_features = ['Energy', 'Fuel_mode', 'Brand', 'Veh_type']\n",
    "numerical_features = [feat for feat in features if feat not in categorical_features]\n",
    "\n",
    "# Creating the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Pipeline for Random Forest\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Pipeline for SVM\n",
    "svm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61db1772-8ba4-4f91-98f4-29729dc35d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n",
      "SVM Accuracy: 0.9987217650148835\n"
     ]
    }
   ],
   "source": [
    "# Fit Random Forest\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "# Predict with Random Forest\n",
    "rf_pred = rf_pipeline.predict(X_test)\n",
    "# Evaluate Random Forest\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "\n",
    "# Fit SVM\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "# Predict with SVM\n",
    "svm_pred = svm_pipeline.predict(X_test)\n",
    "# Evaluate SVM\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(f'SVM Accuracy: {svm_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85afeb6e-7aee-4d1c-a85c-48ea4926d466",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     95809\n",
      "           1       1.00      1.00      1.00     18411\n",
      "\n",
      "    accuracy                           1.00    114220\n",
      "   macro avg       1.00      1.00      1.00    114220\n",
      "weighted avg       1.00      1.00      1.00    114220\n",
      "\n",
      "SVM Accuracy: 0.9987217650148835\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     95809\n",
      "           1       0.99      1.00      1.00     18411\n",
      "\n",
      "    accuracy                           1.00    114220\n",
      "   macro avg       1.00      1.00      1.00    114220\n",
      "weighted avg       1.00      1.00      1.00    114220\n",
      "\n",
      "Optimized Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     95809\n",
      "           1       1.00      1.00      1.00     18411\n",
      "\n",
      "    accuracy                           1.00    114220\n",
      "   macro avg       1.00      1.00      1.00    114220\n",
      "weighted avg       1.00      1.00      1.00    114220\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     95809\n",
      "           1       1.00      1.00      1.00     18411\n",
      "\n",
      "    accuracy                           1.00    114220\n",
      "   macro avg       1.00      1.00      1.00    114220\n",
      "weighted avg       1.00      1.00      1.00    114220\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Fit, predict, and evaluate the Random Forest model\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_pred = rf_pipeline.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}')\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_pred))\n",
    "\n",
    "# Fit, predict, and evaluate the SVM model\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "svm_pred = svm_pipeline.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "print(f'SVM Accuracy: {svm_accuracy}')\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, svm_pred))\n",
    "\n",
    "# Perform Grid Search to optimize the Random Forest model\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_features': ['sqrt'],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2],\n",
    "    'classifier__ccp_alpha': [0.0, 0.01, 0.1]\n",
    "}\n",
    "rf_grid_search = GridSearchCV(estimator=rf_pipeline, param_grid=rf_param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "rf_best_pred = rf_grid_search.best_estimator_.predict(X_test)\n",
    "print(\"Optimized Random Forest Classification Report:\\n\", classification_report(y_test, rf_best_pred))\n",
    "\n",
    "# Perform Grid Search to optimize the SVM model\n",
    "svm_param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['rbf', 'linear'],\n",
    "    'classifier__gamma': ['scale', 'auto']\n",
    "}\n",
    "svm_grid_search = GridSearchCV(estimator=svm_pipeline, param_grid=svm_param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "svm_grid_search.fit(X_train, y_train)\n",
    "svm_best_pred = svm_grid_search.best_estimator_.predict(X_test)\n",
    "print(\"Optimized SVM Classification Report:\\n\", classification_report(y_test, svm_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98bacf43-cf26-41d5-bc37-1ca87ce7bb26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__ccp_alpha': 0.0, 'classifier__max_depth': None, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 100}\n",
      "Best cross-validated accuracy: 0.9999956224589742\n"
     ]
    }
   ],
   "source": [
    "# Grid search parameters for Random Forest\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_features': ['auto', 'sqrt'],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Grid search parameters for SVM\n",
    "svm_param_grid = {\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['rbf', 'linear'],\n",
    "    'classifier__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Grid search parameters for Random Forest\n",
    "rf_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_features': ['sqrt'],  # Updated from 'auto' to 'sqrt'\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2],\n",
    "    'classifier__ccp_alpha': [0.0, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Initialize and fit the GridSearchCV\n",
    "rf_grid_search = GridSearchCV(estimator=rf_pipeline, param_grid=rf_param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and parameters\n",
    "print(\"Best Parameters:\", rf_grid_search.best_params_)\n",
    "print(\"Best cross-validated accuracy:\", rf_grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93d47a83-765a-4ae7-b5c8-dad5d7294391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aec57fb-9982-426d-a5d1-ba5ea49ce995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a DataFrame to view the feature importances\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m feature_importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_names,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_importances_rf\n\u001b[1;32m      9\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest Feature Importances:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_importance_df)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    729\u001b[0m     )\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    682\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "feature_importances_rf = rf_grid_search.best_estimator_.named_steps['classifier'].feature_importances_\n",
    "feature_names = X_train.columns  # Adjust this if your feature names are stored differently\n",
    "\n",
    "# Create a DataFrame to view the feature importances\n",
    "import pandas as pd\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances_rf\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a9b68-df7f-4e7e-9a64-902198b7327b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### coefficients SVM\n",
    "\n",
    "# Check if the SVM model is linear and extract coefficients if true\n",
    "if 'linear' in svm_grid_search.best_params_['classifier__kernel']:\n",
    "    svm_coefficients = svm_grid_search.best_estimator_.named_steps['classifier'].coef_[0]\n",
    "    svm_feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': svm_coefficients\n",
    "    }).sort_values(by='Importance', key=abs, ascending=False)\n",
    "\n",
    "    print(\"SVM Feature Importances (Linear Kernel):\")\n",
    "    print(svm_feature_importance_df)\n",
    "else:\n",
    "    print(\"SVM is using a non-linear kernel; feature importance is not directly interpretable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3de5ac-8a6b-421a-a195-2d73aa251c36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
